{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq6RWfVmO1Vw"
      },
      "source": [
        "__The official website of MetaLLM-GPT:__ https://github.com/JLX0/MetaLLM-GPT\n",
        "\n",
        "__While you can save a copy of this notebook for your convenience, visit the original copy to check for updates of the notebook:__ https://colab.research.google.com/drive/1TWN0mDmbdH1U2i85n7YUV9CKiRG0jJ9h?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vW1OxC-HNoWm"
      },
      "outputs": [],
      "source": [
        "#@title #Initialize\n",
        "#@markdown Run this cell __once and only once__ each time you open this website or resuming from inactivity after a long time \n",
        "!git clone https://github.com/JLX0/MetaLLM-GPT.git\n",
        "!mv  -v /content/MetaLLM-GPT/* /content/\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "H8NMutd1t3lb"
      },
      "outputs": [],
      "source": [
        "#@title #Run MetaLLM-GPT with example settings (optional)\n",
        "#@markdown ####**After choosing an example and configuring the required settings, run this cell to start MetaLLM-GPT**\n",
        "\n",
        "from mg_core import MetaLLM_GPT\n",
        "\n",
        "Example_list= \"Solve an undergraduate math problem\" #@param [\"Generate a deep neural network (require GPU)\", \"Solve an undergraduate math problem\", \"Generate audio from news websites\", \"Design a step in data processing\", \"Optimize a function\", \"Draw a picture of a cat\"]\n",
        "\n",
        "#@markdown ####**Required settings for running examples:**\n",
        "\n",
        "OpenAPI_key=\"type_your_key_here\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown > <font size =\"2\"> The openAPI key you want to use. It can be found [here](https://platform.openai.com/account/api-keys)\n",
        "\n",
        "\n",
        "GPT_version=  \"3.5\" #@param [\"3.5\", \"4\"]\n",
        "\n",
        "#@markdown > <font size =\"2\"> The version of the GPT model\n",
        "\n",
        "#@markdown ####**After MetaLLM-GPT terminates, you can see the generated code by clicking the folder button on the left of the website or running the cell *Display the generated code* down below**\n",
        "\n",
        "\n",
        "Resume= False\n",
        "Privilege=True\n",
        "Environment=None\n",
        "Minimum_number_of_trials= 3\n",
        "Execution_time_limit= 60 \n",
        "Run_indefinitely = False\n",
        "\n",
        "\n",
        "if Example_list == \"Generate a deep neural network\":\n",
        "  Objective=\"create a deep neural network that uses GPU\"\n",
        "  File_name=\"DNN.py\"\n",
        "  Input_expectation=\"1. bs: batch size 2. l:learning rate 3. e: training epochs\"\n",
        "  Output_expectation=\"the validation accuracy of the neural network\"\n",
        "  Execution_time_limit= 300\n",
        "\n",
        "if Example_list == \"Solve an undergraduate math problem\":\n",
        "  Objective=\"Consider the function f(x)=(x^3)((4x+5)^2), for what value of x is f'(x)=0\"\n",
        "  File_name=\"math.py\"\n",
        "  Input_expectation=None\n",
        "  Output_expectation=\"values of x such that f'(x)=0\"\n",
        "\n",
        "if Example_list == \"Generate audio from news websites\":\n",
        "  Objective=\"grab a news article from a news website, summarize the news article, then convert the summary into an audio\"\n",
        "  File_name=\"news_audio.py\"\n",
        "  Input_expectation=\"1.link. the link to the website of the news article. for example, it can be 'https://www.cnbc.com/2023/06/06/apple-ceo-tim-cook-says-ai-companies-need-to-regulate-themselves.html' 2. max_len. the maximum number of sentences in the summary.\"\n",
        "  Output_expectation=\"the audio of the summary and the path to the audio file\"\n",
        "  Execution_time_limit= 300\n",
        "\n",
        "if Example_list == \"Design a step in data processing\":\n",
        "  Objective=\"There is a dataframe of three columns. Each column represents an output/label. Merge the three columns into one column such that each value in the new column is an integer that represents a distinct combination of the three values in the three columns\"\n",
        "  File_name=\"data_process.py\"\n",
        "  Input_expectation=\"1.df_raw. the dataframe with three columns\"\n",
        "  Output_expectation=\"the dataframe with the new column and the number of distinct values in the new column\"\n",
        "\n",
        "if Example_list == \"Optimize a function\":\n",
        "  Objective=\"Optimize the following function f(x,y)=2*(x^2)-1.05*(x^4)+(x^6)/6+xy+y^2 by minimizing f(x,y)\"\n",
        "  File_name=\"optimize.py\"\n",
        "  Input_expectation=\"1. x. initial guesses of x 2. y. initial guesses of y\"\n",
        "  Output_expectation=\"the minimized f(x,y) and the values of x and y corresponds to the minimized value\"\n",
        "\n",
        "\n",
        "if Example_list == \"Draw a picture of a cat\":\n",
        "  Objective=\"Draw a picture of a cat\"\n",
        "  File_name=\"draw.py\"\n",
        "  Input_expectation=None\n",
        "  Output_expectation=\"the image of the cat the path to the image file\"\n",
        "\n",
        "\n",
        "def print_stats():\n",
        "  print(f\"Objective: {Objective}\")\n",
        "  print(f\"File_name: {File_name}\")\n",
        "  print(f\"Input_expectation: {Input_expectation}\")\n",
        "  print(f\"Output_expectation: {Output_expectation}\")\n",
        "  print(f\"Resume: {Resume}\")\n",
        "  print(f\"Privilege: {Privilege}\")\n",
        "  print(f\"Environment: {Environment}\")\n",
        "  print(f\"Minimum_number_of_trials: {Minimum_number_of_trials}\")\n",
        "  print(f\"Execution_time_limit: {Execution_time_limit}\")\n",
        "  print(f\"Run_indefinitely: {Run_indefinitely}\")\n",
        "\n",
        "print(\"----Running MetaLLM-GPT with the following configurations:----\")\n",
        "print_stats()\n",
        "\n",
        "mg_instance = MetaLLM_GPT(Objective=Objective, File_path=File_name,\n",
        "                          Minimum_trial=Minimum_number_of_trials, Resume=Resume, Input=Input_expectation,\n",
        "                          Output=Output_expectation, Time_limit=Execution_time_limit, Privilege=Privilege,\n",
        "                          Environment=Environment,Infinity_mode=Run_indefinitely, Key=OpenAPI_key, \n",
        "                          Model=GPT_version,Verbose=False)\n",
        "\n",
        "mg_instance.run()\n",
        "\n",
        "print(\"----MetaLLM-GPT terminates with the following configurations:----\")\n",
        "print_stats()\n",
        "\n",
        "\n",
        "if Example_list == \"Generate audio from news websites\":\n",
        "  print(\"You should be able to find an audio file by clicking the folder button on the left of the website. You can download the file by clicking the three vertical dots near the file\")\n",
        "\n",
        "if Example_list == \"Draw a picture of a cat\":\n",
        "  print(\"You should be able to find an image file by clicking the folder button on the left of the website. You can download the file by clicking the three vertical dots near the file\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TuBKE_hz2z9-"
      },
      "source": [
        "# Configure additional Python packages (optional)\n",
        "\n",
        "__This step is not necessary and you can leave the cell below blank.__\n",
        "\n",
        "If you want to manually configure additional Python packages that MetaLLM-GPT can use to create/manage codes, install them in the cell below. Note that MetaLLM-GPT can automatically install Python packages by turning on the Privilege option (which is turned on by default). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPlTipW92x6L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Tcha4buMP8JK"
      },
      "outputs": [],
      "source": [
        "#@title #Configure and run MetaLLM-GPT\n",
        "#@markdown ####**After configuring the following settings, run this cell to start MetaLLM-GPT**\n",
        "#@markdown ####**Required settings:**\n",
        "\n",
        "from mg_core import MetaLLM_GPT\n",
        "\n",
        "Objective= \"show me a funny code\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown > <font size =\"2\"> Describe the objective of this code\n",
        "\n",
        "File_name= \"funny.py\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown > <font size =\"2\"> The path to the Python file that is supposed to be read and written by MetaLLM-GPT. If the file does not exist, the file will be created\n",
        "\n",
        "OpenAPI_key=\"type_your_key_here\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown > <font size =\"2\"> The openAPI key you want to use. It can be found [here](https://platform.openai.com/account/api-keys)\n",
        "\n",
        "#@markdown ####**Optional settings:**\n",
        "\n",
        "Resume= False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown > <font size =\"2\"> Whether or not you already have an existing code and want to improve/debug based on it\n",
        "\n",
        "Input_expectation= \"\" #@param {type: \"string\"}\n",
        "\n",
        "if Input_expectation==\"\":\n",
        "  Input_expectation=None\n",
        "\n",
        "#@markdown > <font size =\"2\"> The input arguments for the code. If it is left blank, MetaLLM-GPT assumes the code does not require any input\n",
        "\n",
        "Output_expectation= \"something funny\" #@param {type: \"string\"}\n",
        "\n",
        "if Output_expectation==\"\":\n",
        "  Output_expectation=None\n",
        "\n",
        "#@markdown > <font size =\"2\"> The output (stdout) for the code. If it is left blank, MetaLLM-GPT assumes the code does not require any output\n",
        "\n",
        "Privilege= True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown > <font size =\"2\"> Whether or not you allow MetaLLM-GPT to execute Linux commands, such as installing Python packages from pip. If it is selected, then the setting __Environment__ is ignored.\n",
        "\n",
        "Environment= \"\" #@param {type: \"string\"}\n",
        "\n",
        "if Environment==\"\":\n",
        "  Environment=None\n",
        "\n",
        "#@markdown > <font size =\"2\"> Describe the Python modules in your environment (except the built-in Python modules) which MetaLLM-GPT can use to create the code. You can leave it blank\n",
        "\n",
        "GPT_version=  \"3.5\" #@param [\"3.5\", \"4\"]\n",
        "\n",
        "#@markdown > <font size =\"2\"> The version of the GPT model\n",
        "\n",
        "Minimum_number_of_trials = 3 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown > <font size =\"2\"> The minimum number of iterations MetaLLM-GPT should try even if the code runs smoothly\n",
        "\n",
        "Execution_time_limit = 60 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown > <font size =\"2\"> The time limit that each execution of the code can take in seconds\n",
        "\n",
        "\n",
        "Run_indefinitely = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown > <font size =\"2\"> Whether or not you want MetaLLM-GPT to execute indefinitely until manual termination\n",
        "\n",
        "mg_instance = MetaLLM_GPT(Objective=Objective, File_path=File_name,\n",
        "                          Minimum_trial=Minimum_number_of_trials, Resume=Resume, Input=Input_expectation,\n",
        "                          Output=Output_expectation, Time_limit=Execution_time_limit, Privilege=Privilege,\n",
        "                          Environment=Environment,Infinity_mode=Run_indefinitely, Key=OpenAPI_key, \n",
        "                          Model=GPT_version,Verbose=False)\n",
        "\n",
        "mg_instance.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b50uV4irg68g"
      },
      "outputs": [],
      "source": [
        "#@title #Display the generated code (optional)\n",
        "\n",
        "from base_modules.code_management import meta_python\n",
        "\n",
        "meta_instance=meta_python(File_name)\n",
        "\n",
        "meta_instance.read()\n",
        "\n",
        "print(meta_instance.combined_raw_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8avVR9OL1TvA"
      },
      "outputs": [],
      "source": [
        "#@title #Run the generated code (optional)\n",
        "\n",
        "try:\n",
        "  meta_instance.compile()\n",
        "  exec(meta_instance.compiled_code, globals())\n",
        "except:\n",
        "  from base_modules.code_management import meta_python\n",
        "  meta_instance=meta_python(File_name)\n",
        "  meta_instance.read()\n",
        "\n",
        "  meta_instance.compile()\n",
        "  exec(meta_instance.compiled_code, globals())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_2fw1aXho7Hl"
      },
      "source": [
        "# Manually modify the code (optional)\n",
        "\n",
        "__This step is not necessary and you can leave the cell below blank.__\n",
        "\n",
        "If you want to manually modify the generated code, you can copy the code displayed by the cell __Display the generated code__ or contained in the generated file and then paste it in the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvULf8wLpg9Y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
